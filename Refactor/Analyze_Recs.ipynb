{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dtabuena/Patch_Ephys/blob/main/Refactor/Analyze_Recs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Get Standard Modules'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import pyabf\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import os\n",
        "from scipy.signal import butter,filtfilt\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import warnings\n",
        "import shutil\n",
        "import urllib.request\n",
        "import sklearn as skl\n",
        "import sklearn.mixture as skl_mixture\n",
        "import seaborn as sns\n",
        "# warnings.filterwarnings('ignore')\n",
        "# np.set_printoptions(threshold=sys.maxsize)\n",
        "# clear_output(wait=False)\n",
        "\n",
        "\n",
        "!pip install openpyxl\n",
        "!pip install XlsxWriter"
      ],
      "metadata": {
        "id": "AV0cPU5qPIxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0703062-96d5-48fe-870d-fe0b5822a569"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in c:\\users\\dennis.tabuena\\appdata\\local\\anaconda3\\lib\\site-packages (3.0.10)\n",
            "Requirement already satisfied: et_xmlfile in c:\\users\\dennis.tabuena\\appdata\\local\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: XlsxWriter in c:\\users\\dennis.tabuena\\appdata\\local\\anaconda3\\lib\\site-packages (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_KP8ILeu07BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "face083c-64c4-4d1e-bd4f-00fbc5a8cef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basic_ephys loaded succesfully\n",
            "loaded: Basic_Ephys.ipynb\n",
            "loaded: QC_recoding_dataframe.ipynb\n",
            "loaded: input_resistance_analyzer.ipynb\n",
            "loaded: gain_analyzer.ipynb\n",
            "loaded: latencey_analyzer.ipynb\n",
            "loaded: IV_analyzer.ipynb\n",
            "loaded: rmp_analyzer.ipynb\n",
            "loaded: membrane_analyzer.ipynb\n",
            "loaded: Ephys_wrapper.ipynb\n",
            "loaded: rheobase_analyzer.ipynb\n",
            "loaded: init_func_arg_dicts.ipynb\n"
          ]
        }
      ],
      "source": [
        "'''Get Repositories'''\n",
        "\"run dtabuena's ephys notebooks\"\n",
        "to_import = [\n",
        "            # 'ABF_Quality_Control.ipynb',\n",
        "            'Basic_Ephys.ipynb',\n",
        "            # 'Simple_ABF_tools.ipynb',\n",
        "            # 'fun_math.ipynb',\n",
        "            # 'importing_abfs_from_dropbox.ipynb',\n",
        "            'QC_recoding_dataframe.ipynb',\n",
        "            'input_resistance_analyzer.ipynb',\n",
        "            'gain_analyzer.ipynb',\n",
        "            'latencey_analyzer.ipynb',\n",
        "            'IV_analyzer.ipynb',\n",
        "            'rmp_analyzer.ipynb',\n",
        "            'membrane_analyzer.ipynb',\n",
        "            'Ephys_wrapper.ipynb',\n",
        "            'rheobase_analyzer.ipynb',\n",
        "            'init_func_arg_dicts.ipynb',\n",
        "            ]\n",
        "\n",
        "\n",
        "\n",
        "parent_folder = r\"C:\\Users\\dennis.tabuena\\Gladstone Dropbox\\Dennis Tabuena\\4_Methods\\_Patch_Refactor\"\n",
        "os.chdir(parent_folder)\n",
        "\n",
        "code_dir = 'git_code'\n",
        "# shutil.rmtree(code_dir)\n",
        "os.makedirs(code_dir,exist_ok=True)\n",
        "os.chdir(code_dir)\n",
        "\n",
        "for f in to_import:\n",
        "    try:\n",
        "        git_link = 'https://raw.githubusercontent.com/dtabuena/Patch_Ephys/main/'+f\n",
        "        # print(git_link)\n",
        "        urllib.request.urlretrieve(git_link,f)\n",
        "        %run $f\n",
        "        print('loaded:',f)\n",
        "    except:\n",
        "        print('FAILED:',f)\n",
        "\n",
        "\n",
        "import urllib\n",
        "# response = urllib.request.urlretrieve('https://raw.githubusercontent.com/dtabuena/Resources/main/Matplotlib_Config/Load_FS6.py','Load_FS6.py')\n",
        "# %run Load_FS6.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_func_arg_dicts():\n",
        "    func_dict = {}\n",
        "    arg_dict = {}\n",
        "\n",
        "    # Spike arg defentitions\n",
        "    spike_args_gain={'spike_thresh':10, 'high_dv_thresh': 20,'low_dv_thresh': -5,'window_ms': 3}\n",
        "    spike_args_rheo ={'spike_thresh':15, 'high_dv_thresh': 30,'low_dv_thresh': -15,'window_ms': 2}\n",
        "\n",
        "\n",
        "\n",
        "    func_dict['VC - 3min GapFree']= rmp_analyzer\n",
        "    arg_dict['VC - 3min GapFree'] = [True] # [to_plot?]\n",
        "\n",
        "    func_dict['I0 - 3min GapFree']= rmp_analyzer\n",
        "    arg_dict['I0 - 3min GapFree'] = [True] # [to_plot?]\n",
        "\n",
        "    func_dict['IC - Rheobase']= rheobase_analyzer\n",
        "    arg_dict['IC - Rheobase'] = [spike_args_rheo, True, False, False]  # [spike_args, to_plot, verbose, force_singlespike]\n",
        "\n",
        "    func_dict['IC - Gain - D10pA']= gain_analyzer\n",
        "    arg_dict['IC - Gain - D10pA']= [spike_args_gain, 1, 4, .7,[-60,-80]]  # [spike_args, to_plot [0:2], max_fit_steps, rel_slope_cut, Vh_hilo]\n",
        "\n",
        "    func_dict['IC - Gain - D20pA']= gain_analyzer\n",
        "    arg_dict['IC - Gain - D20pA']= [spike_args_gain, 1, 4, .7,[-60,-80]]  # [spike_args, to_plot [0:2], max_fit_steps, rel_slope_cut, Vh_hilo]\n",
        "\n",
        "    func_dict['IC - Gain - D25pA']= gain_analyzer\n",
        "    arg_dict['IC - Gain - D25pA']= [spike_args_gain, 1, 4, .7,[-60,-80]]  # [spike_args, to_plot [0:2], max_fit_steps, rel_slope_cut, Vh_hilo]\n",
        "\n",
        "    func_dict['IC - Gain - D50pA']= func_dict['IC - Gain - D20pA']\n",
        "    arg_dict['IC - Gain - D50pA']= arg_dict['IC - Gain - D20pA']\n",
        "\n",
        "    func_dict['VC - MemTest-10ms-160ms']= membrane_analyzer\n",
        "    arg_dict['VC - MemTest-10ms-160ms']= [True, False, ['Ra', 'Rm', 'Cm', 'tau',\t'Cmq',\t'Cmf',\t'Cmqf', 'Cm_pc']]  # [to_plot, verbose]\n",
        "\n",
        "    func_dict['IC - Latentcy 800pA-1s']= latencey_analyzer\n",
        "    arg_dict['IC - Latentcy 800pA-1s']= [spike_args_gain, True]  # [spike_args, to_plot]\n",
        "\n",
        "    func_dict['IC - R input']= input_resistance_analyzer\n",
        "    arg_dict['IC - R input']= [[-30, 10] ,True]  # [dVm_limits, to_plot]\n",
        "\n",
        "    # func_dict['VC - Multi IV - 150ms'] = IV_analyzer_v2\n",
        "    # arg_dict['VC - Multi IV - 150ms']= [{'IV_Early':(4.5, 30),'IV_Steady_State':(70,80)} ,[False, True]]  # [measure_windows, to_plot]\n",
        "\n",
        "    func_dict['VC - Multi IV - 150ms'] = IV_analyzer_v3\n",
        "    arg_dict['VC - Multi IV - 150ms']= [[.2, 3],[40,50],True,]  # [Na_window,K_window, to_plot]\n",
        "\n",
        "    return func_dict, arg_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "_kk9-AHD2Sd4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Setup Protocol List\n",
        "VC_prot = ['VC - MemTest-10ms-160ms',\n",
        "           'VC - Multi IV - 150ms',]\n",
        "IC_prot = ['IC - Gain - D10pA',\n",
        "           'IC - Gain - D20pA',\n",
        "           'IC - Gain - D50pA',\n",
        "           'IC - Rheobase',\n",
        "           'IC - R input',\n",
        "           'IC - Latentcy 800pA-1s'\n",
        "           'VC - 3min GapFree',\n",
        "           'I0 - 3min GapFree']\n",
        "\n",
        "\n",
        "# dataset = {'data_name': 'test_data',\n",
        "#            'data_source': r\"C:\\Users\\dennis.tabuena\\Gladstone Dropbox\\Dennis Tabuena\\4_Methods\\_Patch_Refactor\\test_data\",\n",
        "#            'file_naming_scheme': ['Rec_date','geno','sex','age','orientation','slice','cell','type'],\n",
        "#            }\n",
        "\n",
        "dataset = {'data_name': 'test_data',\n",
        "           'data_source': r\"C:\\Users\\dennis.tabuena\\Gladstone Dropbox\\Dennis Tabuena\\4_Methods\\_Patch_Refactor\\test_data\",\n",
        "           'file_naming_scheme': ['year','month','day'],\n",
        "           }\n",
        "\n",
        "analysis_dir =os.path.join(parent_folder,dataset['data_name'])\n",
        "os.makedirs(analysis_dir,exist_ok=True)\n",
        "os.chdir(analysis_dir)\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "im0sAJx5W7EY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a90bd0-8440-45de-c65e-ebfed22573a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C:\\Users\\dennis.tabuena\\Gladstone Dropbox\\Dennis Tabuena\\4_Methods\\_Patch_Refactor\\test_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Scripted Run\n",
        "(unwraped 'ephys wrapper')\n",
        "\"\"\"\n",
        "# init Output\n",
        "results = {}\n",
        "\n",
        "\n",
        "'''Build Basic DF'''\n",
        "abf_recordings_df, protocol_set = catalogue_recs(dataset['data_source'],dataset['file_naming_scheme'])\n",
        "results['abf_recordings_df'] = abf_recordings_df\n",
        "results['protocol_set'] = protocol_set\n",
        "\n",
        "'''# Protocol Look Up Table'''\n",
        "csv_name = cell_prot_lut(abf_recordings_df,protocol_set,csv_name=dataset['data_name']+'_Recording_LookUp')\n",
        "results['prot_lut'] = csv_name\n",
        "\n",
        "\n",
        "func_dict, arg_dict = init_func_arg_dicts()\n",
        "\n",
        "'''Protocol Look Up Table'''\n",
        "abf_recordings_df, problem_recs = analysis_iterator(abf_recordings_df,func_dict,arg_dict,verbose=True)\n",
        "clear_output()\n",
        "display(abf_recordings_df.head(3))\n",
        "abf_recordings_df.to_csv('abf_recordings_df.csv')\n",
        "\n",
        "'''Sort Cells'''\n",
        "cell_df = cell_sorting(abf_recordings_df)\n",
        "results['cell_df'] = cell_df\n",
        "display(cell_df.head(3))\n",
        "cell_df.to_csv('cell_df.csv')"
      ],
      "metadata": {
        "id": "VL-1pLcQVA6I",
        "outputId": "f633bd50-1c2d-42f6-dbf0-09ba144ccbb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'catalogue_recs' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m'''Build Basic DF'''\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m abf_recordings_df, protocol_set \u001b[38;5;241m=\u001b[39m catalogue_recs(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_source\u001b[39m\u001b[38;5;124m'\u001b[39m],dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_naming_scheme\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabf_recordings_df\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m abf_recordings_df\n\u001b[0;32m     12\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotocol_set\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m protocol_set\n",
            "\u001b[1;31mNameError\u001b[0m: name 'catalogue_recs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fast_results = ephys_wrapper_local(dataset,VC_prot,IC_prot,strat_cols=['day'],size_col='Cmq_128.0')"
      ],
      "metadata": {
        "id": "eWeEJGT3NHdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zlzq9ocUU1fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd().replace('\\\\','/'))"
      ],
      "metadata": {
        "id": "n_pJS-NUd8ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fast_results = substitute_gain_rheobase(fast_results,\n",
        "#                                        strat_cols=['Genotype','Age_Bin','Cell_Type'],\n",
        "#                                        age_bin_dict=age_bin_dict)\n"
      ],
      "metadata": {
        "id": "MqYqh8Esdr6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = fast_results"
      ],
      "metadata": {
        "id": "87zsYSUxyN_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "single_val_strat_groups = ['ap_amplitutude',\n",
        "                            'Rmp_mV',\n",
        "                            'Cmq_128.0',\n",
        "                            'Ra_128.0',\n",
        "                            'Rm_128.0',\n",
        "                            'Gain_(HzpA)',\n",
        "                            'inact_current_pA',\n",
        "                            'Rheobase',\n",
        "                            'AP_thresh_US',\n",
        "                            'fast_after_hyperpol',\n",
        "                            'Spike_latency_(ms)',\n",
        "                            'Input_Resistance_MO',\n",
        "                            ]\n",
        "\n",
        "\n",
        "manual_exclusions = ['']\n",
        "exclusion_overide = ['']\n",
        "file_naming_scheme = dataset['file_naming_scheme']\n",
        "strat_df_dict = fast_results['strat_df_dict'].copy()\n",
        "strat_df_dict = {k:strat_df_dict[k] for k in my_order}\n",
        "filtered_dict, fail_dict = final_qc(strat_df_dict,file_naming_scheme,qc_Rmp=-35,qc_AP_amp=20,qc_RR=.20,qc_Ra=np.inf,manual_exclusions=manual_exclusions,exclusion_overide=exclusion_overide)\n",
        "alt_strat_dict = restratify_results(filtered_dict,file_naming_scheme,single_val_strat_groups)\n",
        "\n",
        "resp_curve_list = ['IV_Early_(V_stim)','IV_Early_(I_peak)','IV_Steady_State_(I_mean)','Stim_Levels_(pA)','Spike_Counts']\n",
        "response_curve_data = stratify_response_curve(filtered_dict,resp_curve_list,strat_list=[''])\n",
        "alt_strat_dict.update(response_curve_data)\n",
        "write_strat_dfs_local(alt_strat_dict, dataset['data_name']+'_results_stratified_alternate')\n",
        "print(os.getcwd())\n"
      ],
      "metadata": {
        "id": "SpeFrwv9jbqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3CTYCmoGEFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fGnkrOBGD70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_list = ['Cm_pc_10.0',\n",
        "             'Cmq_160.0',\n",
        "             'Input_Resistance_MO',\n",
        "             'Rm_160.0',\n",
        "             'Rmp_mV',\n",
        "             'Gain_(HzpA)',\n",
        "             'Spike_latency_(ms)',\n",
        "             'Rheobase',\n",
        "             'inact_current_pA',\n",
        "             'ap_amplitutude',\n",
        "             'fast_after_hyperpol',\n",
        "             'sAHP',\n",
        "             'AP_thresh_US',\n",
        "             'ap50_width_ms']\n",
        "\n"
      ],
      "metadata": {
        "id": "uRFbRiwPz45N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oGqkA4m3TCQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_HWCtVNPZSZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prism_csv(data_df,max_replicates=None):\n",
        "    data_type = data_df.columns[0]\n",
        "\n",
        "    # Step 1: Group data by 'Age_Bin' and 'Genotype' and collect values\n",
        "    grouped = data_df.groupby(['Age_Bin', 'Genotype'])[data_type].apply(list).reset_index()\n",
        "\n",
        "    # Step 2: Determine maximum number of replicates based on the size of groups\n",
        "    if max_replicates is None:\n",
        "        max_replicates = grouped[data_type].str.len().max()\n",
        "\n",
        "    # Step 3: Prepare a DataFrame for the multi-level index\n",
        "    results = []\n",
        "\n",
        "    # Replicate numbering function (retained as per your request)\n",
        "    def rep_num(i):\n",
        "        if i == 0:\n",
        "            return \"\"\n",
        "        else:\n",
        "            return f'{i + 1:03}'  # Returns '001', '002', etc.\n",
        "\n",
        "    # Step 4: Generate all possible rows, padding with None where necessary\n",
        "    for _, row in grouped.iterrows():\n",
        "        age_bin = row['Age_Bin']\n",
        "        geno_type = row['Genotype']\n",
        "        values = row[data_type]\n",
        "\n",
        "        # Ensure every group has max_replicates, padding missing values with None\n",
        "        for i in range(max_replicates):\n",
        "            if i < len(values):\n",
        "                # If value exists, use it\n",
        "                results.append({'Age_Bin': age_bin, 'Genotype': geno_type, 'Replicate': rep_num(i), 'Value': values[i]})\n",
        "            else:\n",
        "                # If no value, add a row with None\n",
        "                results.append({'Age_Bin': age_bin, 'Genotype': geno_type, 'Replicate': rep_num(i), 'Value': None})\n",
        "\n",
        "    # Step 5: Create a DataFrame from the results\n",
        "    final_df = pd.DataFrame(results)\n",
        "\n",
        "    # Step 6: Pivot the DataFrame to have Age_Bin as index and multi-level columns, ensuring all replicates exist\n",
        "    pivot_df = final_df.pivot_table(index='Age_Bin', columns=['Genotype', 'Replicate'], values='Value', aggfunc='first')\n",
        "\n",
        "    # Step 7: Ensure all replicate columns exist up to max_replicates, even if some are missing in the data\n",
        "    all_replicates = [rep_num(i) for i in range(max_replicates)]\n",
        "    pivot_df = pivot_df.reindex(columns=pd.MultiIndex.from_product([pivot_df.columns.levels[0], all_replicates]), fill_value=None)\n",
        "\n",
        "    # Step 8: Reset index for easier display\n",
        "    pivot_df.reset_index(inplace=True)\n",
        "\n",
        "    return pivot_df, max_replicates\n",
        "\n",
        "\n",
        "\n",
        "def flatten_multiindex(df):\n",
        "    df.columns = [''.join(map(str, col)).strip() for col in df.columns.values]\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "Gi_m5T1lFFDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTp6NiFenl8-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}